---
jupyter:
  jupytext:
    cell_metadata_json: true
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python slideshow={'slide_type': 'skip'}}
# %load_ext autoreload
# %autoreload 2
```

```{python slideshow={'slide_type': 'skip'}}
from IPython.core.display import Image
```

```{python slideshow={'slide_type': 'slide'}}
Image(filename='../figures//boromir.png')
```

<!-- #region {"slideshow": {"slide_type": "skip"}} -->
<!-- <img src='../img//boromir.png'/> 
<!-- #endregion -->

```{python slideshow={'slide_type': 'skip'}}
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import torch, torchvision
import torch.nn as nn
```

```{python slideshow={'slide_type': 'skip'}}
import sys
sys.path.append('../../mchlearn/')
import utils
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
# Optimizers
<!-- #endregion -->

[An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/)

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
## Gradient Descent
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$\begin{align}
\theta_{t+1}& = \theta^{t}-\eta\nabla_\theta L(\theta_t)
\end{align}
$$
<!-- #endregion -->

```{python slideshow={'slide_type': 'slide'}}
data = np.load("../data/sgd_data.npy").astype('float32')
```

```{python}
sin_example = utils.SinFitExample(data)
```

```{python}
sin_example.display_data();
```

```{python slideshow={'slide_type': 'skip'}}
def fitf(x,o,t):
    return np.sin(x*o+t)

def fitf_tensor(x,o,t):
    return np.moveaxis(np.sin(np.tensordot(np.atleast_1d(x),o,0)+t),0,-1)

def mse(f, x, y, o, t):
        err = f(x,o,t)-y
        return 0.5*np.sum(err*err, axis=-1)/len(x)
```

```{python slideshow={'slide_type': 'skip'}}
t_rxs = torch.from_numpy(data[:400,0])
t_rys = torch.from_numpy(data[:400,1])
```

```{python slideshow={'slide_type': 'skip'}}
loss_f = torch.nn.MSELoss()
```

```{python slideshow={'slide_type': 'slide'}}
rdataset = torch.utils.data.TensorDataset(t_rxs, t_rys)
```

```{python slideshow={'slide_type': 'slide'}}
onebatchloader = torch.utils.data.DataLoader(rdataset, batch_size=len(rdataset), shuffle=False);
```

```{python slideshow={'slide_type': '-'}}
p = torch.FloatTensor([3.2,-0.4])
p.requires_grad_(True)
gd = torch.optim.SGD([p], lr=0.2)
sin_example.run_example(p, gd, onebatchloader);
```

```{python slideshow={'slide_type': 'slide'}}
batch_data_loader = torch.utils.data.DataLoader(rdataset, batch_size=50, shuffle=True)
```

```{python}
p = torch.FloatTensor([3.2,-0.4])
p.requires_grad_(True)
gd = torch.optim.SGD([p], lr=0.2)
sin_example.run_example(p, gd, batch_data_loader);
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
## "Ravine"
<!-- #endregion -->

```{python slideshow={'slide_type': 'skip'}}
rav_par = np.asarray([1.0,10.0]).astype('float32')
```

```{python slideshow={'slide_type': 'skip'}}
ravine_example = utils.RavineExample(rav_par)
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 3])
p.requires_grad_(True);
gd = torch.optim.SGD([p], lr=0.02)
ravine_example.run_example(p, gd,100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 0])
p.requires_grad_(True);
gd = torch.optim.SGD([p], lr=0.02)
ravine_example.run_example(p, gd,100,1.0 );
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
## Gradient Descent with Momentum
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$\begin{align}
v_{t+1}& = \mu v_{t} + (1-\beta)\nabla_\theta L(\theta_t)\\
\theta_{t+1}& = \theta_{t}-\eta v_{t+1}
\end{align}
$$
<!-- #endregion -->

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 3])
p.requires_grad_(True);
gd = torch.optim.SGD([p], lr=0.021, momentum=0.1)
ravine_example.run_example(p, gd,100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 0])
p.requires_grad_(True);
gd = torch.optim.SGD([p], lr=0.021, momentum=0.99)
ravine_example.run_example(p, gd,100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([3.2,-0.4])
p.requires_grad_(True)
gd = torch.optim.SGD([p], lr=0.01, momentum=0.8)
sin_example.run_example(p, gd, batch_data_loader);
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
$$\begin{align}
v_{t+1}& = \mu v_{t} + (1-\beta)\nabla_\theta L(\theta_t)\\
\theta_{t+1}& = \theta_{t}-\eta v_{t+1}
\end{align}
$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_{t+1} = \mu v_{t} + (1-\beta)g_t$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_1 = (1-\beta)g_0$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_2 = \mu (1-\beta)g_0+(1-\beta) g_1$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_3 = \mu\left(\mu (1-\beta)g_0+(1-\beta) g_1\right)+(1-\beta)g_2$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
$$v_3 = \mu^2 (1-\beta)g_0+\mu (1-\beta) g_1
+(1-\beta)g_2$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_t = (1-\beta)\sum_{i=1}^t \mu^{i-1}g_{t-i}$$
<!-- #endregion -->

```{python slideshow={'slide_type': 'slide'}}
ns = np.arange(0,100)
for mu in [0.9, 0.7,0.5, 0.25]:
    plt.plot(ns,mu**ns,'.', label="%4.2f" % (mu,))
plt.legend();
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
## Adam: Adaptive Momentum Estimation 
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$\begin{split}
g_t &= \nabla_\theta L(\theta_t)\\
m_t &= \beta_1 m_{t-1} + (1-\beta_1) g_t \\
v_t &= \beta_2 v_{t-1} + (1-\beta_2) g^2_t \\
\end{split}
$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$\theta_{t+1} = \theta_t -\frac{\eta}{\sqrt{v}+\epsilon}m_t $$
<!-- #endregion -->

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 3])
p.requires_grad_(True);
gd = torch.optim.Adam([p], lr=0.2, betas=(0.2, 0.1))
ravine_example.run_example(p, gd,2100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 0])
p.requires_grad_(True);
gd = torch.optim.Adam([p], lr=0.1, betas=(0.1, 0.2))
ravine_example.run_example(p, gd,2100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([3.2,-0.4])
p.requires_grad_(True)
gd = torch.optim.Adam([p], lr=0.1, betas = (.1,.2 ))
sin_example.run_example(p, gd, batch_data_loader);
```

```{python slideshow={'slide_type': 'slide'}, editable=TRUE}
data = np.load("../data/sgd_data.npy").astype('float32')
rxs = data[:50,0]
rys = data[:50,1]
rxs_valid = data[50:75,0]
rys_valid = data[50:75,1]
```

```{python slideshow={'slide_type': 'fragment'}, editable=TRUE}
t_rxs = torch.from_numpy(rxs).view(-1,1)
t_rys = torch.from_numpy(rys).view(-1,1)
t_rxs_valid = torch.from_numpy(rxs_valid).view(-1,1)
t_rys_valid = torch.from_numpy(rys_valid).view(-1,1)
```

```{python slideshow={'slide_type': 'slide'}, editable=TRUE}
loss_f = nn.MSELoss()
```

```{python slideshow={'slide_type': 'fragment'}, editable=TRUE}
net = nn.Sequential(nn.Linear(in_features=1, out_features=128), nn.ReLU(),
                   nn.Linear(in_features=128, out_features=64), nn.ReLU(), 
                   nn.Linear(in_features=64, out_features=32), nn.ReLU(), 
                   nn.Linear(in_features=32, out_features=1))
```

```{python editable=TRUE, slideshow={'slide_type': 'fragment'}}
optim = torch.optim.Adam(net.parameters(),lr=0.01)
```

```{python slideshow={'slide_type': 'slide'}, editable=TRUE}
# %%time 
loss_list = []
for epoch in range(20000):
    optim.zero_grad()
    pred = net(t_rxs)
    loss = loss_f(pred, t_rys)
    loss.backward()
    with torch.no_grad():
        pred_valid = net(t_rxs_valid)
        loss_valid = loss_f(pred_valid, t_rys_valid)
    loss_list.append((loss.item(), loss_valid))  
    optim.step()
loss_list = np.array(loss_list)  
print(f"train loss = {loss.item():.4f} test loss = {loss_valid:.4f}")
```

```{python editable=TRUE, slideshow={'slide_type': 'slide'}}
plt.plot(loss_list[::10,0], label='train');
plt.plot(loss_list[::10,1], label='test');
plt.legend();plt.title("Loss");
```

```{python slideshow={'slide_type': 'slide'}, editable=TRUE}
xs = torch.linspace(-np.pi, np.pi, 200,)
t_ys = net(xs.view(-1,1))
```

```{python slideshow={'slide_type': 'slide'}, editable=TRUE}
plt.scatter(rxs, rys, color='none', edgecolors='black')
plt.scatter(rxs_valid, rys_valid, color='none', edgecolors='red')
plt.plot(xs,t_ys.detach().numpy());
```
