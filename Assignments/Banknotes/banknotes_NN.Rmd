---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.17.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region editable=true slideshow={"slide_type": ""} -->
# Counterfeit detection
<!-- #endregion -->

The task in this assignment is to detect the  counterfeit banknotes. The data set is based on [banknote authentication Data Set ](https://archive.ics.uci.edu/ml/datasets/banknote+authentication#) from UCI Machine Learning repository. The first three columns denote different parameters obtained from the photographs of the banknotes and last colum provides the label. Frankly as the dataset does not have any description I don't know  which labels corresponds to real and which to counterfeited banknotes. let's assume that label one (positive) denotes the clounterfeits. The set  [banknote_authentication.csv](./data/banknote_authentication.csv) can be found in the `data`  directory.

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as st
```

```{python}
from sklearn.metrics import classification_report, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, roc_auc_score
```

```{python}
import  matplotlib.pyplot as plt
plt.rcParams['figure.figsize']=(8,8)
```

Please insert you  firstname  and name below


# ≈Åukasz Walancik

```{python}
from  sklearn.model_selection import train_test_split
seed = 31287
```

```{python}
data = pd.read_csv('data/banknotes_data.csv')
```

```{python}
data.head()
```

```{python tags=c("skip")}
data.describe()
```

```{python tags=c("skip")}
data.info()
```

```{python}
data_train, data_test = train_test_split(data, test_size=0.2, shuffle=True, stratify=data.loc[:,'counterfeit'], random_state=seed)
```

```{python}
data_train
```

```{python}
lbls_train = data_train['counterfeit']
lbls_test = data_test['counterfeit']
```

```{python}
fig, ax = plt.subplots(1,4, figsize=(22,5))
for i in range(4):
    ax[i].hist(data_train[lbls_train==0].iloc[:,i], bins=32, histtype='step', color='blue')
    ax[i].hist(data_train[lbls_train==1].iloc[:,i], bins=32, histtype='step', color='red')
    ax[i].hist(data_train[lbls_train==0].iloc[:,i], bins=32, histtype='bar', color='lightblue', alpha=0.25)
    ax[i].hist(data_train[lbls_train==1].iloc[:,i], bins=32, histtype='bar', color='orange', alpha =0.25)
```

<!-- #region editable=true slideshow={"slide_type": ""} -->
# Problem 1
<!-- #endregion -->

<!-- #region editable=true slideshow={"slide_type": ""} -->
Train a neural network classifier to predict counterfeit banknotes. Use the features `a0` and `a3`. Calculate the confussion matrix  and AUC score. 
<!-- #endregion -->

```{python editable=TRUE, slideshow={'slide_type': ''}}
import torch
import torch.nn as tnn
```

```{python editable=TRUE, slideshow={'slide_type': ''}}
features= [0, 3]
nf=len(features)
```

```{python editable=TRUE, slideshow={'slide_type': ''}}
features_train = torch.from_numpy(data_train.values[:,features]).to(dtype=torch.float32)
labels_train = torch.from_numpy(data_train.values[:,4:5]).to(dtype=torch.float32)
```

```{python editable=TRUE, slideshow={'slide_type': ''}}
features_test = torch.from_numpy(data_test.values[:,features]).to(dtype=torch.float32)
labels_test = torch.from_numpy(data_test.values[:,4:5]).to(dtype=torch.float32)
```

```{python editable=TRUE, slideshow={'slide_type': ''}}
model = tnn.Sequential(tnn.Linear(in_features=nf, out_features=1), tnn.Sigmoid())
```

```{python editable=TRUE, slideshow={'slide_type': ''}}
from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, roc_auc_score
```

```{python editable=TRUE, slideshow={'slide_type': ''}}
y_true = labels_test.numpy()
with torch.no_grad():
  y_proba = model(features_test);
  y_predicted = 1*(y_proba>0.5)
```

```{python editable=TRUE, slideshow={'slide_type': ''}}
accuracy_score(y_true, y_pred=y_predicted)
```

## Useful Functions


I wanted to compare different models and optimizers, so I prepared some functions that I will re-use later

```{python}
def train_model(model, loss_function, optimizer_class, number_of_epochs, learning_rate):
    loss_list = []
    optimizer = optimizer_class(model.parameters(), lr=learning_rate)
    for epoch in range(num_epochs):
        optimizer.zero_grad()

        pred = model(features_train)

        loss = loss_function(pred, labels_train)

        loss.backward()

        with torch.no_grad():
            pred_test = model(features_test)
            loss_test = loss_function(pred_test, labels_test)
        loss_list.append((loss.item(), loss_test))  

        optimizer.step()

    return np.array(loss_list)
```

```{python}
def show_losses(loss_list_1, loss_list_2, label_1, label_2, title, skip):
    plt.plot(loss_list_1[::skip, 0], label=f'{label_1} Train Loss', color='blue', linestyle='-')
    plt.plot(loss_list_1[::skip, 1], label=f'{label_1} Test Loss', color='darkblue', linestyle='--')
    
    plt.plot(loss_list_2[::skip, 0], label=f'{label_2} Train Loss', color='red', linestyle='-')
    plt.plot(loss_list_2[::skip, 1], label=f'{label_2} Test Loss', color='darkred', linestyle='--')
    
    plt.title(f'Comaprison of loss values for different {title}')
    plt.xlabel('Epochs')
    plt.ylabel('Loss value')
    plt.legend()
    plt.tight_layout() 
    plt.show()

```

## Trainig preparation


In this section I will create a loss function, optimizer, and set number of epochs


### Model


### Logistic regression model

```{python}
model = tnn.Sequential(tnn.Linear(in_features=nf, out_features=1), tnn.Sigmoid())
```

### Model with more layers

```{python}
model_2 = tnn.Sequential(
    tnn.Linear(in_features=nf, out_features=32),
    tnn.ReLU(),
    tnn.Linear(in_features=32, out_features=16),
    tnn.ReLU(),
    tnn.Linear(in_features=16, out_features=1),
    tnn.Sigmoid()
)
```

## Loss function


I am using BCELoss. I've red that it's better for binary classification problems

```{python}
loss_function = tnn.BCELoss()
```

## Optimizer


I am using Adam optimizer.

```{python}
optimizer_Adam = torch.optim.Adam(model.parameters(), lr=0.01)
```

## Number of epochs

```{python}
num_epochs = 10000
```

## Models Comparison


When I started working on this problem, I noticed that the 'simple' model that You have provided, does not get 'better' with more epochs. I wanted to see if more 'comples' models behave differently

```{python}
loss_list_1 = train_model(model, loss_function, torch.optim.Adam, num_epochs, 0.01)
```

```{python}
loss_list_2 = train_model(model_2, loss_function, torch.optim.Adam, num_epochs, 0.01)
```

```{python}
show_losses(loss_list_1, loss_list_2, "Simple Model", "Complex Model", "models", 10)
```

As we can see, the 'simple model' achieves loss value around 0.32, and complex model gets better loss value, but after some time it overfits, and the test loss value gets worse and worse.  
We can also see that it takes less than 100 epochs to get the optimal loss value


## Accuracy after training


I will be using the 'simple' model You've provided for the rest of the notebook

```{python}
y_true = labels_test.numpy()
with torch.no_grad():
    y_proba = model(features_test)
    y_predicted = 1*(y_proba > 0.5)

y_predicted_np = y_predicted.numpy()
y_proba_np = y_proba.numpy()

print(f"Accuracy: {accuracy_score(y_true, y_predicted_np):.4f}")
```

## Confusion Matrix

```{python}
cm = confusion_matrix(y_true, y_predicted_np, normalize='true')
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()
```

## AUC Score and ROC Curve

```{python}
fpr, tpr, thresholds = roc_curve(y_true, y_proba_np)
roc_auc = roc_auc_score(y_true, y_proba_np)

plt.plot(fpr, tpr, label=f'Train ROC (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for features a0 and a3')
plt.grid()
plt.legend(loc='lower right')
plt.show()
```

```{python}

```
